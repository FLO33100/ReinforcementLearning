{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines.deepq.policies import MlpPolicy as DQN_MlpPolicy\n",
    "from stable_baselines import A2C, PPO2, DQN\n",
    "from stable_baselines.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from aequam_env import AequamEnv\n",
    "from fpdf import FPDF\n",
    "from backtest_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmail_user = 'dorian.lagadec@aequamcapital.com'  \n",
    "gmail_password = 'Aequaminternship0#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(df, start_int = 0, base = 100):\n",
    "    return(df/np.array(df.iloc[start_int,:])*base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obs_1 = pd.read_csv('data/dataset1.csv', index_col = 0, parse_dates=True, usecols = lambda x: x not in ['Equi_weighted'])\n",
    "df_obs_2 = pd.read_csv('data/dataset2.csv', index_col = 0, parse_dates=True, usecols = lambda x: x not in ['Equi_weighted'])\n",
    "df_obs_3 = pd.read_csv('data/dataset3.csv', index_col = 0, parse_dates=True, usecols = lambda x: x not in ['Equi_weighted'])\n",
    "df_obs_4 = pd.read_csv('data/dataset4.csv', index_col = 0, parse_dates=True, usecols = lambda x: x not in ['Equi_weighted'])\n",
    "df_obs_5 = pd.read_csv('data/dataset5.csv', index_col = 0, parse_dates=True, usecols = lambda x: x not in ['Equi_weighted'])\n",
    "df_obs_6 = pd.read_csv('data/dataset6.csv', index_col = 0, parse_dates=True, usecols = lambda x: x not in ['Equi_weighted'])\n",
    "df_obs_7 = pd.read_csv('data/dataset7.csv', index_col = 0, parse_dates=True, usecols = lambda x: x not in ['Equi_weighted'])\n",
    "\n",
    "def propagate_index(from_df, to_df):\n",
    "    return(to_df.loc[from_df.index,:])\n",
    "\n",
    "df_prices_base = pd.read_csv('data/test.csv', index_col = 0, parse_dates=True, usecols = [i for i in range(7)])\n",
    "\n",
    "df_prices_all = df_prices_base.copy()\n",
    "df_prices_on_off = pd.DataFrame(df_prices_base.mean(axis=1), columns = ['Equally_weighted'])\n",
    "df_prices_modes = pd.concat([df_prices_base[['Value','Momentum','Carry']].mean(axis=1), \\\n",
    "                            df_prices_on_off,\\\n",
    "                            df_prices_base[['Quality','Profitability','Size']].mean(axis=1) ], axis=1)\n",
    "df_prices_modes.columns = ['Offensive','Equally_weighted','Defensive']\n",
    "\n",
    "def df_obs_and_prices(num, asset):\n",
    "    if num == 1:\n",
    "        df_obs = df_obs_1\n",
    "    elif num == 2:\n",
    "        df_obs = df_obs_2\n",
    "    elif num == 3:\n",
    "        df_obs = df_obs_3\n",
    "    elif num == 4:\n",
    "        df_obs = df_obs_4\n",
    "    elif num == 5:\n",
    "        df_obs = df_obs_5\n",
    "    elif num == 6:\n",
    "        df_obs = df_obs_6\n",
    "    else:\n",
    "        df_obs = df_obs_7\n",
    "    \n",
    "    \n",
    "    if asset == 'all':\n",
    "        df_prices = df_prices_all\n",
    "    elif asset == 'on_off':\n",
    "        df_prices = df_prices_on_off\n",
    "    else:\n",
    "        df_prices = df_prices_modes\n",
    "    return(df_obs, df_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filter = 5\n",
    "# n_episodes = 100\n",
    "lookback_window = 20\n",
    "reward_type = 'delayed'\n",
    "total_timesteps = 2000\n",
    "transaction_smoothing = 2\n",
    "algo = 'ppo2'\n",
    "num_df = 5\n",
    "asset = 'modes'\n",
    "random_proportion = 1\n",
    "prefix = '_'\n",
    "print_report=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper(n_filter = n_filter, lookback_window = lookback_window, reward_type = reward_type, \\\n",
    "            total_timesteps = total_timesteps, transaction_smoothing = transaction_smoothing, \\\n",
    "            algo = algo, num_df = num_df, asset = asset, \\\n",
    "            random_proportion = random_proportion, prefix = prefix, print_report=print_report):\n",
    "    \n",
    "    if random.random() < random_proportion :\n",
    "        \n",
    "        df_obs, df_prices = df_obs_and_prices(num_df, asset)\n",
    "        df_prices = propagate_index(from_df=df_obs, to_df=df_prices_all)\n",
    "        \n",
    "        env = DummyVecEnv([lambda: AequamEnv(df_obs.iloc[::n_filter], df_prices.iloc[::n_filter],\\\n",
    "                                             lookback_window = lookback_window, reward_type = reward_type,\\\n",
    "                                             transaction_smoothing = transaction_smoothing)])\n",
    "\n",
    "        if algo == 'dqn':   \n",
    "            model = DQN(DQN_MlpPolicy, env, param_noise=True, verbose=0, tensorboard_log='tmp/')\n",
    "        elif algo == 'ppo2' :   \n",
    "            model = PPO2(MlpPolicy, env, verbose=0, tensorboard_log='tmp/')\n",
    "            total_timesteps *= 10\n",
    "        else:\n",
    "            print(1/0)\n",
    "\n",
    "        model.learn(total_timesteps=total_timesteps)\n",
    "\n",
    "        env.envs[0].play_last_episode(model)\n",
    "\n",
    "        if print_report:\n",
    "            env.envs[0].print_pdf_report(filename(prefix, n_filter, lookback_window, reward_type, total_timesteps,\\\n",
    "                                                 transaction_smoothing, algo, num_df, asset))\n",
    "        send_report(gmail_user, gmail_password)\n",
    "\n",
    "    return('Done')\n",
    "\n",
    "vectorized_wrapper = np.vectorize(wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ParameterGrid({\"n_filter\": [1, 5, 10, 20],\n",
    "                      \"lookback_window\": [5, 10, 20, 30],\n",
    "                      \"reward_type\": ['delayed', 'daily'],\n",
    "                      \"total_timesteps\": [1000, 10000, 50000, 100000, 500000],\n",
    "                      \"transaction_smoothing\": [1, 2, 5, 10, 20],\n",
    "                      \"algo\": ['dqn','ppo2'],\n",
    "                      \"num_df\": [1, 2, 3, 4, 5, 6, 7],\n",
    "                      \"asset\": ['all','on_off','modes']})\n",
    "grid_df = pd.DataFrame(grid)\n",
    "\n",
    "random_proportion = 1\n",
    "prefix = 'wrapper_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0904 18:26:50.579475 36804 deprecation_wrapper.py:119] From C:\\Users\\Avisia\\Anaconda3\\envs\\env_dorian\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:98: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0904 18:26:50.582468 36804 deprecation_wrapper.py:119] From C:\\Users\\Avisia\\Anaconda3\\envs\\env_dorian\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:107: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0904 18:26:50.586459 36804 deprecation_wrapper.py:119] From C:\\Users\\Avisia\\Anaconda3\\envs\\env_dorian\\lib\\site-packages\\stable_baselines\\deepq\\dqn.py:123: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0904 18:26:50.587455 36804 deprecation_wrapper.py:119] From C:\\Users\\Avisia\\Anaconda3\\envs\\env_dorian\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0904 18:26:50.589448 36804 deprecation_wrapper.py:119] From C:\\Users\\Avisia\\Anaconda3\\envs\\env_dorian\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:359: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0904 18:26:50.593438 36804 deprecation_wrapper.py:119] From C:\\Users\\Avisia\\Anaconda3\\envs\\env_dorian\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:189: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0904 18:26:50.614412 36804 deprecation.py:323] From C:\\Users\\Avisia\\Anaconda3\\envs\\env_dorian\\lib\\site-packages\\stable_baselines\\deepq\\policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0904 18:26:51.433303 36804 deprecation.py:323] From C:\\Users\\Avisia\\Anaconda3\\envs\\env_dorian\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:268: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0904 18:26:51.728479 36804 deprecation_wrapper.py:119] From C:\\Users\\Avisia\\Anaconda3\\envs\\env_dorian\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:415: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "W0904 18:26:52.241480 36804 deprecation_wrapper.py:119] From C:\\Users\\Avisia\\Anaconda3\\envs\\env_dorian\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:449: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0904 18:26:52.428037 36804 deprecation_wrapper.py:119] From C:\\Users\\Avisia\\Anaconda3\\envs\\env_dorian\\lib\\site-packages\\stable_baselines\\common\\base_class.py:880: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email sent!\n",
      "Email sent!\n",
      "Email sent!\n",
      "Email sent!\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "vectorized_wrapper(n_filter = grid_df['n_filter'].values, lookback_window = grid_df['lookback_window'].values,\\\n",
    "                   reward_type = grid_df['reward_type'].values, \\\n",
    "            total_timesteps = grid_df['total_timesteps'].values, transaction_smoothing = grid_df['transaction_smoothing'].values, \\\n",
    "            algo = grid_df['algo'].values, num_df = grid_df['num_df'].values, asset = grid_df['asset'].values, \\\n",
    "            random_proportion = random_proportion, prefix = prefix, print_report=print_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# wrapper(total_timesteps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# obs = env.reset()\n",
    "# for i in range(env.envs[0].total_window -env.envs[0].lookback_window):\n",
    "#     action, _states = model.predict(obs, deterministic=False)\n",
    "#     obs, rewards, done, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.envs[0].play_last_episode(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.envs[0].play_last_episode(model)\n",
    "\n",
    "# env.envs[0].print_pdf_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.reset()\n",
    "# for i in range(len(df_obs.iloc[::n_filter]) -lookback_window-1):\n",
    "# #     i += 1\n",
    "# #     print(i)\n",
    "#     action, _states = model.predict(obs)\n",
    "#     obs, rewards, done, info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.envs[0].plot_last_episode(save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# env.envs[0].plot_positions(save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.envs[0].df_render.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
